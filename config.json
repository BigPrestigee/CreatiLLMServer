{
    "model_dir": "qwen/Qwen-1_8B-Chat-Int4",
    "tensor_parallel_size": 1,
    "gpu_memory_utilization": 0.6,
    "quantization": "gptq",
    "dtype": "float16",
    "max_history" : 50
}